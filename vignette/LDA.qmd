---
title: "STAT325: Analysis of Frankenstein"
author: "Justin Papagelis (jpapagelis24@amherst.edu)"
date: "`r Sys.Date()`"
date-format: iso
format: pdf
editor: source
bibliography: bib/ref.bib
toc: true
toc_depth: 3
fig_caption: true
---

```{r, include = FALSE}
library(Frankenstein)
library(dplyr)
library(tidyr)
library(tidytext)
library(topicmodels)
library(ggplot2)
library(stringr)

number_of_topics <- 12
```

## Introduction

*Frankenstein; or, The Modern Prometheus* [@Shelley], written by Mary Shelley in 1818, is a groundbreaking work in the literary world that interweaves elements of Gothic literature with early ideas of science fiction. The novel tells the cautionary tale of Victor Frankenstein, a scientist who creates a sentient being, only to reject it which leads to tragic consequences for both the creator and the creature. The novel explores themes of ambition, responsibility, and the search for identity. *Frankenstein* has become an important dialogue about the limits of scientific exploration, the responsibilities of creators, and the societal implications of isolation and rejection. It raises essential questions about the nature of humanity, the pursuit of knowledge, and the consequences of ambition unhindered by ethical considerations. Additionally, *Frankenstein* has had an enduring influence on popular culture and media. The narrative unfolds through the perspectives of three distinct narrators: Captain Robert Walton, Victor Frankenstein, and The Creature. The use of multiple narrators allows Shelley to explore different viewpoints and layer the narrative with complex emotions and ethical questions, providing a rich tapestry of human experience and moral contemplation. Each narrative reflects each individual's experiences, biases, and emotional states, contributing to a many different perspectives of the same story. For this analysis, I would like to see if the sections told by different narrators vary from each other. A short example of the first couple of lines of each narrator's first section is shown in Table \ref{example_text}.

```{r, extract lines function}
get_first_n_lines <- function(section_number, letter_or_chapter, n) {
  # Filter data for the specific section and section type
  
  section_data <- Frankenstein |>
    filter(section == section_number, section_type == letter_or_chapter)
  
  # Extract the first n lines of text, if there are at least n lines available
  if (nrow(section_data) >= n) {
    lines <- section_data$text[1:n]
  } else {
    lines <- section_data$text[1:nrow(section_data)]
  }
  combined_lines <- paste(lines, collapse = " ")
  combined_lines <- paste0(combined_lines, " ...")
  return(combined_lines)
}
```


```{r}
example_text <- tibble(
  Narrator = c("Captain Robert Walton", "Victor Frankenstein", "The Creature"),
  `Example Text` = c(get_first_n_lines(1, "letter", 15), # Walton's first POV
                   get_first_n_lines(1, "chapter", 15), # Victor's first POV
                   get_first_n_lines(11, "chapter", 15)) # Creature's first POV
) 
```


```{r}
# Create the table
example_text |>
  kableExtra::kable(booktabs = TRUE, format = "latex", 
                    linesep = "\\addlinespace", 
                    caption = "Example Narrative Sections in 
                    Frankenstein\\label{example_text}") |>
  kableExtra::column_spec(1, width = "3cm") |>  
  kableExtra::column_spec(2, width = "12cm") |> 
  kableExtra::kable_styling(latex_options = "scale_down")
```

## Methods

The novel is told using a framing device which is basically a story within a story within a story. More specifically, the narrators for each section are as follows:

-   Walton: *Letters 1-4*

-   Frankenstein: *Chapters 1-10*

-   The Creature: *Chapters 11-16*

-   Frankenstein: *Chapters 17-24.5*

-   Walton: *Rest of Chapter 24*

For this part of my analysis, I use Latent Dirichlet Allocation (LDA) which was first used in machine learning by David Blei, Andrew Ng and Michael I. Jordan [@Blei]. It is a method of topic modelling to try that I will use to see if there is evidence of the framing device within the novel. In other words, I would like to see if LDA can detect the parts of the story that are written by the same narrator. To do this in R, I will utilize methods explained in "tidytext" [@tidytext], as well as the `topicmodels` package [@topicmodels] and the `stringr` package [@stringr].

## Initial Wrangling

To begin, the novel is pre-processed to remove common stop words, numbers, and other miscellaneous words. To create a unique label for each chapter, I combined the section and the section type as well as removed "section 0" which was the table of contents. To further wrangle the data, I split Chapter 24 into two parts, each corresponding to one narrator. I also tokenized the novel which splits the novel into individual words. See Table \ref{token} for an example of the tokenized data.

Next, I created the document-word matrix and an LDA model using a value of `k=``r number_of_topics` which means that the LDA model will isolate topics. I decided to separate the novel into `r number_of_topics` topics because since the novel is long and there are many plot lines, this greater number of topics will help identify distinct topics. 

```{r, message = FALSE}
# Pre-processing
other_stop_words <- tibble(  
     word = paste(c(0:24, "Chapter", "11th", "_to")))

section_names <- c("letter 1", "letter 2", "letter 3", "letter 4", "chapter 1", 
              "chapter 2", "chapter 3", "chapter 4", "chapter 5", "chapter 6", 
              "chapter 7", "chapter 8", "chapter 9", "chapter 10", "chapter 11", 
              "chapter 12", "chapter 13", "chapter 14", "chapter 15", 
              "chapter 16", "chapter 17", "chapter 18", "chapter 19", 
              "chapter 20", "chapter 21", "chapter 22", "chapter 23",
              "chapter 24", "letter 24.5")



narrators <- 
  tibble(section_names) |> 
  mutate(
    section_number = readr::parse_number(section_names),
    narrator = case_when(
      str_detect(section_names, "letter") ~ "Captain Walton",
      str_detect(section_names, "chapter") 
      & section_number <= 10 ~ "Victor Frankenstein",
      str_detect(section_names, "chapter") 
      & between(section_number, 11, 16) ~ "The Creature",
      str_detect(section_names, "chapter") 
      & section_number >= 17 ~ "Victor Frankenstein"
    )
  ) |> 
  rename(document = "section_names")

# Clean and tokenize novel
# note: line 6854 is where Walton's POV starts back up in chapter 24
Frankenstein_LDA <- Frankenstein |>
  mutate(section = ifelse(line >= 6854, 24.5, section), 
         section_type = ifelse(line >= 6854, "letter", section_type)) |>
  filter(section != 0) |>
  mutate(section_label = paste(section_type,section)) |>
  select(-section,-section_type) |>
  unnest_tokens(word, text) |>
  anti_join(stop_words) |>
  anti_join(other_stop_words) |>
  mutate(section_label = factor(section_label, levels = section_names))

Frankenstein_LDA |>
  filter(section_label %in% "chapter 1") |>
  head(20) |>
  kableExtra::kable(booktabs = TRUE, col.names = c("Line", "Section", "Word"),
                    caption = "Example of Tokenized Novel\\label{token}") 

# Create the document-word matrix
dtm <- Frankenstein_LDA |>
  count(section_label, word) |>
  cast_dtm(section_label, word, n)

# Create LDA model using value of k and seed
lda_model <- LDA(dtm, k = number_of_topics, control = list(seed = 1)) 
```

## Beta Analysis

First, I looked at the per-topic-per-word probabilities to extract the top words that are used in each of the topics. An example of the beta values for the word "death" are shown in Table \ref{beta_death}. As you can see, Topic 5 has a much larger beta value than the other topics which suggests that "death" is a word more associated with Topic 5. Then I created a graphic using `ggplot` [@ggplot] to show the most common words in each of the topics. The graphic is shown below in Figure \ref{top_terms}. 

```{r }
# Per-topic-per-word probabilities
topics_beta <- tidy(lda_model, matrix = "beta")

topics_beta |>
  filter(term == "death")   |>
  kableExtra::kable(booktabs = TRUE, col.names = c("Topic", "Term", "Beta"),
                    caption = "Beta Values for \"Death\"\\label{beta_death}", 
                    digits = 4) 
```





```{r top_terms, fig.width = 8, fig.height = 12, fig.cap = "Figure of most common words in each topic\\label{top_terms}"}

# Per-topic-per-word probabilities
topics_beta <- tidy(lda_model, matrix = "beta")

# Get the top terms
top_terms <- topics_beta |>
  group_by(topic) |>
  slice_max(beta, n = 5) |>
  ungroup() |>
  arrange(topic, -beta)

topic_names <- c("1: \"The Creature's birth\"", "2: \"Frankenstein's Studies\"", 
                 "3: \"Justine's Trial\"", "4: \"Walton in Antarctica\"", 
                 "5: \"Frankenstein's Guilt\"", 
                 "6: \"Frankenstein on the Run\"",
                 "7: \"Frankenstein at Home\"", "8: \"Creating the Creature\"", 
                 "9: \"Frankenstein in Antarctica\"", 
                 "10: \"Frankenstein's Love\"", "11: \"The Creature Learning\"", 
                 "12: \"The Creature Betrayed\"")

# Create visual
top_terms |>
  mutate(term = reorder_within(term, beta, topic),
         topic = factor(topic, levels = 1:12, labels = topic_names)) |>
  ggplot(aes(beta, term, fill = factor(topic, levels = topic_names))) +
  theme_minimal() +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", ncol = 2) +
  scale_y_reordered() +
  labs(x = "Beta-value", y = "Words", fill = "Topic", 
       title = "Most Common Words by Topic") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

In particular, I chose to focus on three of the topics: 1: The Creature's Birth, 4: Walton in Antarctica, and 10: Frankenstein's Love.

Topic 1 shows that the most common words are found, cottage, wood, fire, and day. This topic gives very simple words that seem to be when The Creature is telling his story and thus has a limited knowledge of the world and talks of basic utilities and needs. He is talking about the day that he was born and first experienced the world.

Topic 4's most common words were ice, friend, eyes, voice, feel. This most likely represents Captain Robert Walton who was on an expedition to Antarctica when he met Victor Frankenstein and the The Creature. These words all seem ominous and make sense with all the death that occurs in the frozen landscape at the culmination of the novel.

Topic 10's most common words were Elizabeth, life, father, day, happiness, and death. This seems to be Victor Frankenstein's narration because one of his main devotions in life was towards his adopted sister, Elizabeth. His father was also an important figure in his life. He also "gave life" to his creation: The Creature.

## Gamma Analysis

After, that, I examined the per-document-per-topic probabilities ("gamma") which gives the estimated proportion of words from that document that are generated from that topic. The visual is shown in Figure \ref{gamma}. For example, this model predicts that a large portion of the words from Chapter 11 and Chapter 12 are generated from Topic 1. Looking back, we can see that this topic (The Creature's Birth) corresponded to the beginning of The Creature's life/narration which is true since The Creature's narration spans from Chapter 11 to Chapter 16. Using our other example chapters, we can see that Letter 4 and Letter 24.5 both are estimated to be generated from Topic 4 (Walton in Antarctica) which corresponds to Captain Robert Walton's narration! And finally, Chapter 4 and Chapter 22 are estimated to be generated from Topic 10 (Frankenstein's Love) which we had decided was Victor Frankenstein's narration. See Table \ref{gamma_chap} for the gamma values used in the examples above.

```{r}

# Per-document-per-topic probabilities
topics_gamma <- tidy(lda_model, matrix = "gamma") |>
  mutate(document = factor(document, levels = section_names))

gamma_with_narrator <- topics_gamma |>
  pivot_wider(names_from = topic, values_from = gamma) |>
  inner_join(narrators, by = "document") |>
  pivot_longer(cols = 2:13, names_to = "topic", values_to = "gamma") |>
  mutate(document = factor(document, levels = section_names))

gamma_with_narrator <- gamma_with_narrator |>
  mutate(topic_POV = case_when(topic %in% c(4) ~ "Walton Topic",
      topic %in% c(2,3,5,6,7,9,10)  ~ "Frankenstein Topic",
      topic %in% c(1,8,11,12)  ~ "Creature Topic")) 

topics_gamma |>
  filter(document %in% c("chapter 11", "chapter 12", "letter 4", "letter 24.5", 
                         "chapter 4", "chapter 22")) |>
  pivot_wider(names_from = topic, values_from = gamma) |>
  kableExtra::kable(booktabs = TRUE, col.names = c("Section", 1:12),
              caption = "Gamma Values for Example Chapters\\label{gamma_chap}", 
                    digits = 2) 
```


```{r, fig.width = 8, fig.height = 10, fig.cap = "Per-section-per-topic probabilities\\label{gamma}", warning = FALSE}
# Create visual
walton_pov <- gamma_with_narrator |>
  mutate(topic = factor(topic, levels = 1:12, labels = topic_names)) |>
  filter(topic_POV == "Walton Topic") |>
  ggplot(aes(x = document, y = gamma, group = topic, color = topic)) +
  geom_rect(xmin = 0, xmax = 4, ymin = 0, ymax = 2, alpha = 0.01, 
            fill = 'lightblue', inherit.aes = FALSE) +
  geom_rect(xmin = 28.5, xmax = 29, ymin = 0, ymax = 2, alpha = 0.01, 
            fill = 'lightblue', inherit.aes = FALSE) +
  geom_point() + geom_smooth(se = FALSE, span = 0.5, method = 'loess', 
                             formula = 'y - x') + theme_minimal() +
  labs(x = "Section", y = "Topic Proportion", fill = "Topic", 
       title = "Gamma Topic Distribution Across Frankenstein With Walton's 
       Topics Highlighted") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom") + coord_cartesian(ylim = c(0, 1)) 

frankenstein_pov <- gamma_with_narrator |>
  mutate(topic = factor(topic, levels = 1:12, labels = topic_names)) |>
  filter(topic_POV == "Frankenstein Topic") |>
  ggplot(aes(x = document, y = gamma, group = topic, color = topic)) +
  geom_rect(xmin = 4, xmax = 14, ymin = 0, ymax = 2, alpha = 0.01, 
            fill = 'pink', inherit.aes = FALSE) +
  geom_rect(xmin = 21, xmax = 28.5, ymin = 0, ymax = 2, alpha = 0.01, 
            fill = 'pink', inherit.aes = FALSE) +
  geom_point() + geom_smooth(se = FALSE, span = 0.5, method = 'loess', 
                             formula = 'y - x') + theme_minimal() +
  labs(x = "Section", y = "Topic Proportion", fill = "Topic", 
       title = "Gamma Topic Distribution Across Frankenstein With 
       Frankenstein's Topics Highlighted") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom") + coord_cartesian(ylim = c(0, 1)) 

creature_pov <- gamma_with_narrator |>
  mutate(topic = factor(topic, levels = 1:12, labels = topic_names)) |>
  filter(topic_POV == "Creature Topic") |>
  ggplot(aes(x = document, y = gamma, group = topic, color = topic)) +
  geom_rect(xmin = 14, xmax = 21, ymin = 0, ymax = 2, alpha = 0.01, 
            fill = 'lightgreen', inherit.aes = FALSE) +
  geom_point() + geom_smooth(se = FALSE, span = 0.5, method = 'loess', 
                             formula = 'y - x') + theme_minimal() +
  labs(x = "Section", y = "Topic Proportion", fill = "Topic", 
       title = "Gamma Topic Distribution Across Frankenstein With The 
       Creature's Topics Highlighted") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom") + coord_cartesian(ylim = c(0, 1)) 

gridExtra::grid.arrange(walton_pov, frankenstein_pov, creature_pov, ncol = 1)

```


## Shiny App
Additionally, I created a Shiny app that can be used to further analyze the sentence structure within *Frankenstein*. To accomplish this, we used the `cleanNLP` package [@cleannlp] as well as the `plotly` package [@plotly].

In particular, you can see the distribution of different parts of speech by chapter as well as select a certain chapter and see the frequencies of the parts of speech in specific sentences. Click here to open the app: \href{https://r.amherst.edu/apps/jpapagelis24/Frankenstein/}{Frankenstein Shiny App}. 

If we look at the "Parts of Speech" Tab, we can see an interesting distribution of proper nouns over the chapters and you can accurately see where the narrator sections should be broken up. There seem to be spikes in the center of most of the narrator's point of view sections. The rest of the parts of speech seem to be similar across different narrator sections. 

Additionally, looking at sentence structure, there does not seem to be any distinguishing features that set the different narrator sections apart. The longest sentence is told by Victor Frankenstein and contain 159 words.

## Conclusion
Overall, the LDA topic modeling provided insights into the narrative structure within *Frankenstein* and was able to identify several elements of the framing device employed throughout the text. We were semi-successful in seeing how the topics correlated with certain narrator sections.
Although the model was not perfect as there were numerous topics with words dispersed across the entire book, refining the parameters could enhance its precision and effectiveness in distinguishing distinct narrative elements.

\newpage

## References
